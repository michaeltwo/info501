{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is what the input is for the visualization functions\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "    \"recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "    \"f1_score\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, model.predict_proba(X_test)[:, 1], multi_class=\"ovr\", average=\"weighted\"),\n",
    "    \"model\" : model\n",
    "    \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    xgb.plot_importance(model_metrics['model'], importance_type='weight')  # Use 'weight', 'gain', or 'cover'\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model_metrics):\n",
    "    cm = model_metrics.get(\"confusion_matrix\")\n",
    "    class_labels=[\"Control\", \"Sepsis\"]\n",
    "\n",
    "    if cm is not None:\n",
    "        # Plot confusion matrix using seaborn heatmap\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "                    xticklabels=class_labels, \n",
    "                    yticklabels=class_labels)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Confusion matrix is not available in the model metrics.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
